<html>

<head>
<style type="text/css">
.knitr .inline {
  background-color: #f7f7f7;
  border:solid 1px #B0B0B0;
}
.error {
	font-weight: bold;
	color: #FF0000;
}
.warning {
	font-weight: bold;
}
.message {
	font-style: italic;
}
.source, .output, .warning, .error, .message {
	padding: 0 1em;
  border:solid 1px #F7F7F7;
}
.source {
  background-color: #f5f5f5;
}
.rimage .left {
  text-align: left;
}
.rimage .right {
  text-align: right;
}
.rimage .center {
  text-align: center;
}
.hl.num {
  color: #AF0F91;
}
.hl.str {
  color: #317ECC;
}
.hl.com {
  color: #AD95AF;
  font-style: italic;
}
.hl.opt {
  color: #000000;
}
.hl.std {
  color: #585858;
}
.hl.kwa {
  color: #295F94;
  font-weight: bold;
}
.hl.kwb {
  color: #B05A65;
}
.hl.kwc {
  color: #55aa55;
}
.hl.kwd {
  color: #BC5A65;
  font-weight: bold;
}
</style>
<title>GLM on Text Sparse Matrix</title>
<style>
body {  
      width:800px;
      background-color: white;
      margin-left: auto;
      margin-right:auto;
      padding:5px;
     }
</style>
</head>

<body>
<h1><ins>GLM on Text Sparse Matrix</ins></h1>
<p style="font-family:courier;font-size:110%;">Shan Chen<br>
Jan 2016</p>
<p>This file records the thought process of predicting people's review of albums with information such as dimension of photos and words used in photo cation. It will basically contain three parts:<br>
1. EDA<br>
2. 1 gram Vectorization and Sparse Matrix Generation<br>
3. GLMNET Modeling and Validation<br>
4. Prediction and Submission</p>
<h1>1. EDA</h1>
<p> Loading packages and data set</p>
<div class="chunk" id="unnamed-chunk-1"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'knitr'</span><span class="hl std">)</span>
<span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'ggplot2'</span><span class="hl std">)</span>
<span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'gridExtra'</span><span class="hl std">)</span>
<span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'sqldf'</span><span class="hl std">)</span>
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: gsubfn
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: proto
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: RSQLite
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: DBI
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'dplyr'</span><span class="hl std">)</span>
</pre></div>
<div class="message"><pre class="knitr r">## 
## Attaching package: 'dplyr'
</pre></div>
<div class="message"><pre class="knitr r">## The following object is masked from 'package:gridExtra':
## 
##     combine
</pre></div>
<div class="message"><pre class="knitr r">## The following objects are masked from 'package:stats':
## 
##     filter, lag
</pre></div>
<div class="message"><pre class="knitr r">## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'stringi'</span><span class="hl std">)</span>
<span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'Matrix'</span><span class="hl std">)</span>
<span class="hl kwd">library</span><span class="hl std">(</span><span class="hl str">'glmnet'</span><span class="hl std">)</span>
</pre></div>
<div class="message"><pre class="knitr r">## Loading required package: foreach
</pre></div>
<div class="message"><pre class="knitr r">## Loaded glmnet 2.0-5
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl std">train</span><span class="hl kwb">&lt;-</span><span class="hl kwd">read.csv</span><span class="hl std">(</span><span class="hl str">&quot;C:\\Users\\Shan\\Desktop\\Photo Quality Prediction\\training.csv&quot;</span><span class="hl std">)</span>
</pre></div>
</div></div>
<h2>1.1 Non-text Features Visualization</h2>
<p>Converting "good" data type from int to factor
<div class="chunk" id="unnamed-chunk-2"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">train</span><span class="hl opt">$</span><span class="hl std">good</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">as.factor</span><span class="hl std">(train</span><span class="hl opt">$</span><span class="hl std">good)</span>
</pre></div>
</div></div>
<p>Boxplots:</p>
<div class="chunk" id="unnamed-chunk-3"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">g1</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=good,</span> <span class="hl kwc">y</span><span class="hl std">=latitude))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_boxplot</span><span class="hl std">()</span>
<span class="hl std">g2</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=good,</span> <span class="hl kwc">y</span><span class="hl std">=longitude))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_boxplot</span><span class="hl std">()</span>
<span class="hl std">g3</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=good,</span> <span class="hl kwc">y</span><span class="hl std">=width))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_boxplot</span><span class="hl std">()</span>
<span class="hl std">g4</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=good,</span> <span class="hl kwc">y</span><span class="hl std">=height))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_boxplot</span><span class="hl std">()</span>
<span class="hl std">g5</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=good,</span> <span class="hl kwc">y</span><span class="hl std">=size))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_boxplot</span><span class="hl std">()</span>
<span class="hl std">a</span><span class="hl kwb">=</span><span class="hl kwd">grid.arrange</span><span class="hl std">( g1,g2,g3,g4,g5,</span> <span class="hl kwc">nrow</span><span class="hl std">=</span><span class="hl num">3</span><span class="hl std">,</span><span class="hl kwc">ncol</span><span class="hl std">=</span><span class="hl num">2</span><span class="hl std">)</span>
</pre></div>
</div><div class="rimage default"><img src="figure/unnamed-chunk-3-1.png" title="plot of chunk unnamed-chunk-3" alt="plot of chunk unnamed-chunk-3" class="plot" /></div></div>
<p>Density plots:</p>
<div class="chunk" id="unnamed-chunk-4"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">g1</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=latitude,</span> <span class="hl kwc">color</span><span class="hl std">=good))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_density</span><span class="hl std">()</span>
<span class="hl std">g2</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=longitude,</span> <span class="hl kwc">color</span><span class="hl std">=good))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_density</span><span class="hl std">()</span>
<span class="hl std">g3</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=width,</span> <span class="hl kwc">color</span><span class="hl std">=good))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_density</span><span class="hl std">()</span>
<span class="hl std">g4</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span><span class="hl std">=height,</span> <span class="hl kwc">color</span><span class="hl std">=good))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_density</span><span class="hl std">()</span>
<span class="hl std">g5</span><span class="hl kwb">=</span><span class="hl kwd">ggplot</span><span class="hl std">(train,</span> <span class="hl kwd">aes</span><span class="hl std">(</span><span class="hl kwc">x</span> <span class="hl std">= size,</span><span class="hl kwc">color</span><span class="hl std">=good))</span> <span class="hl opt">+</span> <span class="hl kwd">geom_density</span><span class="hl std">()</span>
<span class="hl std">a</span><span class="hl kwb">=</span><span class="hl kwd">grid.arrange</span><span class="hl std">( g1,g2,g3,g4,g5,</span> <span class="hl kwc">nrow</span><span class="hl std">=</span><span class="hl num">3</span><span class="hl std">,</span><span class="hl kwc">ncol</span><span class="hl std">=</span><span class="hl num">2</span><span class="hl std">)</span>
</pre></div>
</div><div class="rimage default"><img src="figure/unnamed-chunk-4-1.png" title="plot of chunk unnamed-chunk-4" alt="plot of chunk unnamed-chunk-4" class="plot" /></div></div>
<p>From above plots, it looks like the distribution of non-text variable for both good and not good albums are similar, it may mean that, in terms of latitude variable, for a given latitude area, it is hard to judge if the album would be viewed good or not only through the latitude effect. This is possible due to lack of other vital variables, e.g., longitude, size, text information, or it's simply because there is no obvious linear relationship between latitude and goodness of albums which might make sense if it's the situation that any negative and positive latitude area  both have good albums and bad albums (lack of other more specific information).</p>
<h2>1.2 Logistic GLM to only Non-text Features</h2>
<p>In order to address our guess of lack of other important features, we first add all the non-text features into a glm model (since response variable--good has two values).<br>
Just out of curiousity, I would like to know if glm model would perform well if I only used non-text predictors.</p>
<div class="chunk" id="unnamed-chunk-5"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl com">#subset only non-text information out of train date set</span>
<span class="hl std">train</span><span class="hl kwb">&lt;-</span><span class="hl std">train[,</span><span class="hl kwd">c</span><span class="hl std">(</span><span class="hl num">1</span><span class="hl opt">:</span><span class="hl num">6</span><span class="hl std">,</span><span class="hl num">10</span><span class="hl std">)]</span>
<span class="hl std">fit1</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">glm</span><span class="hl std">(good</span> <span class="hl opt">~</span><span class="hl std">latitude</span><span class="hl opt">+</span><span class="hl std">longitude</span><span class="hl opt">+</span><span class="hl std">width</span><span class="hl opt">+</span><span class="hl std">height</span><span class="hl opt">+</span><span class="hl std">size ,</span> <span class="hl kwc">family</span> <span class="hl std">=</span> <span class="hl str">&quot;binomial&quot;</span><span class="hl std">,</span> <span class="hl kwc">data</span><span class="hl std">=train)</span>
<span class="hl kwd">summary</span><span class="hl std">(fit1)</span>
</pre></div>
<div class="output"><pre class="knitr r">## 
## Call:
## glm(formula = good ~ latitude + longitude + width + height + 
##     size, family = &quot;binomial&quot;, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4663  -0.7752  -0.6534   1.1837   2.2307  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.8235829  0.0953425 -19.127  &lt; 2e-16 ***
## latitude    -0.0034867  0.0005674  -6.145 8.02e-10 ***
## longitude    0.0048920  0.0001475  33.158  &lt; 2e-16 ***
## width        0.0013556  0.0001130  12.001  &lt; 2e-16 ***
## height       0.0001489  0.0001146   1.299    0.194    
## size         0.0038511  0.0002653  14.516  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 46324  on 40261  degrees of freedom
## Residual deviance: 44366  on 40256  degrees of freedom
## AIC: 44378
## 
## Number of Fisher Scoring iterations: 4
</pre></div>
</div></div>
<p>It seems all variables except for height are significant predictors for goodness of albums meaning that glm kind of addressed our feature linearity problem once we add more others features in.</p>
<p>Calculate in-sample error rate</p>
<p>Error rate</p>
<div class="chunk" id="unnamed-chunk-6"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">train.predict</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">predict</span><span class="hl std">(fit1,</span><span class="hl kwc">type</span> <span class="hl std">=</span> <span class="hl str">&quot;response&quot;</span><span class="hl std">)</span>
<span class="hl std">predict.good</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">ifelse</span><span class="hl std">(train.predict</span> <span class="hl opt">&gt;=</span> <span class="hl num">0.50</span><span class="hl std">,</span> <span class="hl num">1</span><span class="hl std">,</span><span class="hl num">0</span><span class="hl std">)</span>
<span class="hl std">predict.match</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">ifelse</span><span class="hl std">(predict.good</span> <span class="hl opt">==</span> <span class="hl std">train</span><span class="hl opt">$</span><span class="hl std">good,</span><span class="hl num">1</span><span class="hl std">,</span><span class="hl num">0</span><span class="hl std">)</span>
<span class="hl std">correct_rate_insample</span><span class="hl kwb">&lt;-</span><span class="hl kwd">sum</span><span class="hl std">(predict.match)</span><span class="hl opt">/</span><span class="hl kwd">nrow</span><span class="hl std">(train)</span>
<span class="hl std">error_rate_insample</span> <span class="hl kwb">&lt;-</span> <span class="hl num">1</span><span class="hl opt">-</span><span class="hl std">correct_rate_insample</span>
<span class="hl std">error_rate_insample</span>
</pre></div>
<div class="output"><pre class="knitr r">## [1] 0.2635736
</pre></div>
</div></div>
<p>Error rate is 0.2635736 which is kinda low, then I consider adding the text information and conduct a glmnet model to deal with text variable.</p>
<h1>2. 1 gram Vectorization and Sparse Matrix Generation</h1>
<h2>2.1 Why Need Text Information</h2>
<div class="chunk" id="unnamed-chunk-7"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">train</span><span class="hl kwb">&lt;-</span><span class="hl kwd">read.csv</span><span class="hl std">(</span><span class="hl str">&quot;C:\\Users\\Shan\\Desktop\\Photo Quality Prediction\\training.csv&quot;</span><span class="hl std">)</span>
<span class="hl std">test</span><span class="hl kwb">&lt;-</span><span class="hl kwd">read.csv</span><span class="hl std">(</span><span class="hl str">&quot;C:\\Users\\Shan\\Desktop\\Photo Quality Prediction\\test.csv&quot;</span><span class="hl std">)</span>
<span class="hl std">complete</span> <span class="hl kwb">&lt;-</span><span class="hl kwd">bind_rows</span><span class="hl std">(train, test)</span><span class="hl com"># Union the data together vertically</span>
</pre></div>
<div class="warning"><pre class="knitr r">## Warning in rbind_all(x, .id): Unequal factor levels: coercing to character

## Warning in rbind_all(x, .id): Unequal factor levels: coercing to character

## Warning in rbind_all(x, .id): Unequal factor levels: coercing to character
</pre></div>
<div class="source"><pre class="knitr r"><span class="hl kwd">head</span><span class="hl std">(complete)</span>
</pre></div>
<div class="output"><pre class="knitr r">## Source: local data frame [6 x 10]
## 
##      id latitude longitude width height  size                name
##   (int)    (int)     (int) (int)  (int) (int)               (chr)
## 1     1       45        16   604    453    31            454 1659
## 2     2       21       -87   720    534    43            2068 483
## 3     3       38       -97   720    540    71                 802
## 4     4       38      -122   604    453    24                    
## 5     5      -29        24   720    540    13             1766 20
## 6     6      -21        56   604    453    58 1380 1441 1832 1559
## Variables not shown: description (chr), caption (chr), good (int)
</pre></div>
</div></div>
<p>Our interests is to find out which words in name, description and caption of an album would tend to give a satisfying quality result and which ones would not, in order to address such a problem, I first extract out all of the words in those three columns to generate quite a lot new word tokens features(1-gram, only one word), and fill in the cell with 1 if the album contains the corresponding word and 0 if not.</p>
<h2>2.2 R Functions for Sparse Matrix Generation</h2>
<p>I use the below R functions to generate such a <b>large sparse matrix</b>.</p>
<div class="chunk" id="unnamed-chunk-8"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">name</span><span class="hl kwb">&lt;-</span><span class="hl std">complete</span><span class="hl opt">$</span><span class="hl std">name</span>
<span class="hl std">description</span><span class="hl kwb">&lt;-</span><span class="hl std">complete</span><span class="hl opt">$</span><span class="hl std">description</span>
<span class="hl std">caption</span><span class="hl kwb">&lt;-</span><span class="hl std">complete</span><span class="hl opt">$</span><span class="hl std">caption</span>

<span class="hl com">#1 gram Vectorization</span>
<span class="hl std">tokens</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">stri_split_fixed</span><span class="hl std">(name,</span> <span class="hl str">' '</span><span class="hl std">)</span>
<span class="hl std">token_vector</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">unlist</span><span class="hl std">(tokens)</span>
<span class="hl std">bagofwords_name</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">unique</span><span class="hl std">(token_vector)</span>
<span class="hl std">n_tokens</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">sapply</span><span class="hl std">(tokens, length)</span>
<span class="hl std">i</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">rep</span><span class="hl std">(</span><span class="hl kwd">seq_along</span><span class="hl std">(n_tokens), n_tokens)</span>
<span class="hl std">j</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">match</span><span class="hl std">(token_vector, bagofwords_name)</span>
<span class="hl std">sparsematrix_name</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">sparseMatrix</span><span class="hl std">(</span><span class="hl kwc">i</span><span class="hl std">=i,</span> <span class="hl kwc">j</span><span class="hl std">=j,</span> <span class="hl kwc">x</span><span class="hl std">=</span><span class="hl num">1L</span><span class="hl std">)</span>
<span class="hl kwd">colnames</span><span class="hl std">(sparsematrix_name)</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">paste</span><span class="hl std">(bagofwords_name,</span><span class="hl str">'in Name'</span><span class="hl std">)</span>

<span class="hl std">tokens</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">stri_split_fixed</span><span class="hl std">(description,</span> <span class="hl str">' '</span><span class="hl std">)</span>
<span class="hl std">token_vector</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">unlist</span><span class="hl std">(tokens)</span>
<span class="hl std">bagofwords_description</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">unique</span><span class="hl std">(token_vector)</span>
<span class="hl std">n_tokens</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">sapply</span><span class="hl std">(tokens, length)</span>
<span class="hl std">i</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">rep</span><span class="hl std">(</span><span class="hl kwd">seq_along</span><span class="hl std">(n_tokens), n_tokens)</span>
<span class="hl std">j</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">match</span><span class="hl std">(token_vector, bagofwords_description)</span>
<span class="hl std">sparsematrix_description</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">sparseMatrix</span><span class="hl std">(</span><span class="hl kwc">i</span><span class="hl std">=i,</span> <span class="hl kwc">j</span><span class="hl std">=j,</span> <span class="hl kwc">x</span><span class="hl std">=</span><span class="hl num">1L</span><span class="hl std">)</span>
<span class="hl kwd">colnames</span><span class="hl std">(sparsematrix_description)</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">paste</span><span class="hl std">(bagofwords_description,</span><span class="hl str">'in Description'</span><span class="hl std">)</span>

<span class="hl std">tokens</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">stri_split_fixed</span><span class="hl std">(caption,</span> <span class="hl str">' '</span><span class="hl std">)</span>
<span class="hl std">token_vector</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">unlist</span><span class="hl std">(tokens)</span>
<span class="hl std">bagofwords_caption</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">unique</span><span class="hl std">(token_vector)</span>
<span class="hl std">n_tokens</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">sapply</span><span class="hl std">(tokens, length)</span>
<span class="hl std">i</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">rep</span><span class="hl std">(</span><span class="hl kwd">seq_along</span><span class="hl std">(n_tokens), n_tokens)</span>
<span class="hl std">j</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">match</span><span class="hl std">(token_vector, bagofwords_caption)</span>
<span class="hl std">sparsematrix_caption</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">sparseMatrix</span><span class="hl std">(</span><span class="hl kwc">i</span><span class="hl std">=i,</span> <span class="hl kwc">j</span><span class="hl std">=j,</span> <span class="hl kwc">x</span><span class="hl std">=</span><span class="hl num">1L</span><span class="hl std">)</span>
<span class="hl kwd">colnames</span><span class="hl std">(sparsematrix_caption)</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">paste</span><span class="hl std">(bagofwords_caption,</span><span class="hl str">'in Caption'</span><span class="hl std">)</span>
<span class="hl com">#cbind three sparse matrix with other non-text columns</span>
<span class="hl std">x</span><span class="hl kwb">&lt;-</span><span class="hl kwd">cbind</span><span class="hl std">(</span><span class="hl kwd">as.matrix</span><span class="hl std">(complete[,</span><span class="hl kwd">c</span><span class="hl std">(</span><span class="hl num">1</span><span class="hl opt">:</span><span class="hl num">6</span><span class="hl std">)]),sparsematrix_name,sparsematrix_description,sparsematrix_caption)</span>
<span class="hl kwd">dim</span><span class="hl std">(x)</span><span class="hl com">#dimension is correct, x is the complete sparse matrix without the good column</span>
</pre></div>
<div class="output"><pre class="knitr r">## [1] 52262  6299
</pre></div>
</div></div>
<div class="chunk" id="unnamed-chunk-9"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl com">#have a look at a little piece of the matrix</span>
<span class="hl std">x[</span><span class="hl num">1</span><span class="hl opt">:</span><span class="hl num">20</span><span class="hl std">,</span><span class="hl num">1</span><span class="hl opt">:</span><span class="hl num">20</span><span class="hl std">]</span>
</pre></div>
<div class="output"><pre class="knitr r">## 20 x 20 sparse Matrix of class &quot;dgCMatrix&quot;
</pre></div>
<div class="message"><pre class="knitr r">##    [[ suppressing 20 column names 'id', 'latitude', 'longitude' ... ]]
</pre></div>
<div class="output"><pre class="knitr r">##                                                          
##  [1,]  1  45   16 604 453  31 1 1 . . . . . . . . . . . .
##  [2,]  2  21  -87 720 534  43 . . 1 1 . . . . . . . . . .
##  [3,]  3  38  -97 720 540  71 . . . . 1 . . . . . . . . .
##  [4,]  4  38 -122 604 453  24 . . . . . 1 . . . . . . . .
##  [5,]  5 -29   24 720 540  13 . . . . . . 1 1 . . . . . .
##  [6,]  6 -21   56 604 453  58 . . . . . . . . 1 1 1 1 . .
##  [7,]  7  42  -73 540 720   2 . . . . . . . . . . . . 1 1
##  [8,]  8  26  -80 604 452  49 . . . . . . . . . . . . . .
##  [9,]  9  15  100 604 453  12 . . . . . . . . . . . . . .
## [10,] 10  41  -74 640 478 361 . . . . . . . . . . . . . 1
## [11,] 11  39  -97 604 453  76 . . . . . . . . . . . . . .
## [12,] 12  52    6 453 604  21 . . . . . . . . . . . . . .
## [13,] 13  41  -87 299 448  10 . . . . . 1 . . . . . . . .
## [14,] 14 -29   24 604 453  80 . . . . . . . . . . . . . .
## [15,] 15 -10  -76 604 453  30 . . . . . . . . . . . . . .
## [16,] 16  34  -84 403 604  47 . . 1 . . . . . . . . . . .
## [17,] 17  39  -99 720 540 128 . . . . . 1 . . . . . . . .
## [18,] 18  33 -113 453 604  18 . . . . . . . . . . . . . .
## [19,] 19  10  -84 604 453  89 . . . . . . . . . . . . . .
## [20,] 20  -5  120 428 253  10 . . . . . . . . . . . . . .
</pre></div>
</div></div>
<p>Now we have the sparse matrix that containing 6299 columns, we are finally ready to conduct a powerful GLMNET algorithm to this large sparse matrix.</p>
<h1>3. GLMNET Modeling and Validation</h1>
<p>Split x into two parts; one is train the other is test.</p>
<div class="chunk" id="unnamed-chunk-10"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">x_train</span> <span class="hl kwb">&lt;-</span> <span class="hl std">x[</span><span class="hl num">1</span><span class="hl opt">:</span><span class="hl num">40262</span><span class="hl std">,]</span>
<span class="hl std">x_test</span> <span class="hl kwb">&lt;-</span> <span class="hl std">x[</span><span class="hl num">40263</span><span class="hl opt">:</span><span class="hl num">52262</span><span class="hl std">,]</span>
</pre></div>
</div></div>
<h2>3.1 GLMNET Modeling </h2>
<div class="chunk" id="unnamed-chunk-11"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">fit2</span><span class="hl kwb">=</span><span class="hl kwd">glmnet</span><span class="hl std">(x_train,train</span><span class="hl opt">$</span><span class="hl std">good,</span><span class="hl kwc">family</span><span class="hl std">=</span><span class="hl str">&quot;binomial&quot;</span><span class="hl std">)</span>
</pre></div>
</div></div>
<p>Use x_train data to predict train$good and then calculate in-sample error rate.</p>
<div class="chunk" id="unnamed-chunk-12"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">train.predict</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">predict</span><span class="hl std">(fit2,</span><span class="hl kwc">newx</span><span class="hl std">=x_train,</span> <span class="hl kwc">s</span><span class="hl std">=</span><span class="hl num">0.001</span><span class="hl std">,</span><span class="hl kwc">type</span> <span class="hl std">=</span> <span class="hl str">&quot;response&quot;</span><span class="hl std">)</span><span class="hl com">#s is the value of lambda</span>
<span class="hl std">predict.good</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">ifelse</span><span class="hl std">(train.predict</span> <span class="hl opt">&gt;=</span> <span class="hl num">0.50</span><span class="hl std">,</span> <span class="hl num">1</span><span class="hl std">,</span><span class="hl num">0</span><span class="hl std">)</span>
<span class="hl std">predict.match</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">ifelse</span><span class="hl std">(predict.good</span> <span class="hl opt">==</span> <span class="hl std">train</span><span class="hl opt">$</span><span class="hl std">good,</span><span class="hl num">1</span><span class="hl std">,</span><span class="hl num">0</span><span class="hl std">)</span>
<span class="hl std">correct_rate_insample</span><span class="hl kwb">&lt;-</span><span class="hl kwd">sum</span><span class="hl std">(predict.match)</span><span class="hl opt">/</span><span class="hl kwd">nrow</span><span class="hl std">(train)</span>
<span class="hl std">error_rate_insample</span> <span class="hl kwb">&lt;-</span> <span class="hl num">1</span><span class="hl opt">-</span><span class="hl std">correct_rate_insample</span>
<span class="hl std">error_rate_insample</span>
</pre></div>
<div class="output"><pre class="knitr r">## [1] 0.1717004
</pre></div>
</div></div>
<p>Error rate is 0.1717004 which is better than only using non-text information as predictors.</p>
<h2>3.2 Cross Validation</h2>
<p> We see that our model's performance has been improved after we take in text predictors, however I think we still need a bit more work on applying the model to some out-of sample and check the consistence of the model.
<div class="chunk" id="unnamed-chunk-13"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl com">#cross validation (carve out x_train, the first 1 fouth of the x_train set is treated as the validation set)</span>
<span class="hl std">valid</span> <span class="hl kwb">&lt;-</span> <span class="hl std">train[</span><span class="hl num">1</span><span class="hl opt">:</span><span class="hl num">10000</span><span class="hl std">,]</span>
<span class="hl std">train</span> <span class="hl kwb">&lt;-</span> <span class="hl std">train[</span><span class="hl num">10001</span><span class="hl opt">:</span><span class="hl num">40262</span><span class="hl std">,]</span>
<span class="hl std">x_valid</span> <span class="hl kwb">&lt;-</span> <span class="hl std">x_train[</span><span class="hl num">1</span><span class="hl opt">:</span><span class="hl num">10000</span><span class="hl std">,]</span>
<span class="hl std">x_train</span> <span class="hl kwb">&lt;-</span> <span class="hl std">x_train[</span><span class="hl num">10001</span><span class="hl opt">:</span><span class="hl num">40262</span><span class="hl std">,]</span>

<span class="hl std">fit3</span><span class="hl kwb">=</span><span class="hl kwd">glmnet</span><span class="hl std">(x_train,train</span><span class="hl opt">$</span><span class="hl std">good,</span><span class="hl kwc">family</span><span class="hl std">=</span><span class="hl str">&quot;binomial&quot;</span><span class="hl std">)</span>
</pre></div>
</div></div>
<p>Then predict out of sample error rate of valid data.</p>
<div class="chunk" id="unnamed-chunk-14"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">valid.predict</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">predict</span><span class="hl std">(fit3,</span><span class="hl kwc">newx</span><span class="hl std">=x_valid,</span> <span class="hl kwc">s</span><span class="hl std">=</span><span class="hl num">0.001</span><span class="hl std">,</span><span class="hl kwc">type</span> <span class="hl std">=</span> <span class="hl str">&quot;response&quot;</span><span class="hl std">)</span><span class="hl com">#s is the value of lambda</span>
<span class="hl std">predict.good</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">ifelse</span><span class="hl std">(valid.predict</span> <span class="hl opt">&gt;=</span> <span class="hl num">0.50</span><span class="hl std">,</span> <span class="hl num">1</span><span class="hl std">,</span><span class="hl num">0</span><span class="hl std">)</span>
<span class="hl std">predict.match</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">ifelse</span><span class="hl std">(predict.good</span> <span class="hl opt">==</span> <span class="hl std">valid</span><span class="hl opt">$</span><span class="hl std">good,</span><span class="hl num">1</span><span class="hl std">,</span><span class="hl num">0</span><span class="hl std">)</span>
<span class="hl std">correct_rate_outofsample</span><span class="hl kwb">&lt;-</span><span class="hl kwd">sum</span><span class="hl std">(predict.match)</span><span class="hl opt">/</span><span class="hl kwd">nrow</span><span class="hl std">(valid)</span>
<span class="hl std">error_rate_outofsample</span> <span class="hl kwb">&lt;-</span> <span class="hl num">1</span><span class="hl opt">-</span><span class="hl std">correct_rate_outofsample</span>
<span class="hl std">error_rate_outofsample</span>
</pre></div>
<div class="output"><pre class="knitr r">## [1] 0.2256
</pre></div>
</div></div>
<p>Out of sample error rate is a bit higher than in sample's possibily due to the train sample size becomes smaller but is still lower than our first model (non-text model--fit1)'s error rate.</p>
<h1>4. Prediction and Submission</h1>
<h2>4.1 Prediction</h2>
<p>Predict the x_test set using our fist whole x_train glmnet model--fit2</p>
<div class="chunk" id="unnamed-chunk-15"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">test</span><span class="hl opt">$</span><span class="hl std">predict</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">predict</span><span class="hl std">(fit2,</span><span class="hl kwc">newx</span><span class="hl std">=x_test,</span> <span class="hl kwc">s</span><span class="hl std">=</span><span class="hl num">0.001</span><span class="hl std">,</span><span class="hl kwc">type</span> <span class="hl std">=</span> <span class="hl str">&quot;response&quot;</span><span class="hl std">)</span><span class="hl com">#s is the value of lambda</span>
<span class="hl std">test</span><span class="hl opt">$</span><span class="hl std">predict.good</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">ifelse</span><span class="hl std">(test</span><span class="hl opt">$</span><span class="hl std">predict</span> <span class="hl opt">&gt;=</span> <span class="hl num">0.50</span><span class="hl std">,</span> <span class="hl num">1</span><span class="hl std">,</span><span class="hl num">0</span><span class="hl std">)</span>
</pre></div>
</div></div>
<h2>4.2 Submission</h2>
<p>Choose only two columns (id and prediction result) as our final entry; give column names and write to a CSV file.</p>
<div class="chunk" id="unnamed-chunk-16"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl std">submission</span> <span class="hl kwb">&lt;-</span> <span class="hl kwd">cbind</span><span class="hl std">(test</span><span class="hl opt">$</span><span class="hl std">id,test</span><span class="hl opt">$</span><span class="hl std">predict.good)</span>
<span class="hl kwd">colnames</span><span class="hl std">(submission)</span> <span class="hl kwb">&lt;-</span><span class="hl kwd">c</span><span class="hl std">(</span><span class="hl str">&quot;id&quot;</span><span class="hl std">,</span><span class="hl str">'good'</span><span class="hl std">)</span>
<span class="hl kwd">write.csv</span><span class="hl std">(submission,</span> <span class="hl kwc">file</span> <span class="hl std">=</span> <span class="hl str">'submission.csv'</span><span class="hl std">,</span> <span class="hl kwc">row.names</span> <span class="hl std">= F)</span>
</pre></div>
</div></div>
<p>Have a look at the format of our submission.</p>
<div class="chunk" id="unnamed-chunk-17"><div class="rcode"><div class="source"><pre class="knitr r"><span class="hl kwd">head</span><span class="hl std">(submission)</span>
</pre></div>
<div class="output"><pre class="knitr r">##         id good
## [1,] 40265    0
## [2,] 40266    0
## [3,] 40267    0
## [4,] 40268    0
## [5,] 40269    1
## [6,] 40270    0
</pre></div>
</div></div>
<p>Later on I will work on some other feature engineering tools such as PCA and SVD, in order to reduce dimensionality of large sparse matrix to see if such model manipulation could lower a bit the error rate.
</p>
</body>

</html>
